{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T10:58:34.510091Z","iopub.execute_input":"2022-04-04T10:58:34.510394Z","iopub.status.idle":"2022-04-04T10:58:34.522578Z","shell.execute_reply.started":"2022-04-04T10:58:34.510363Z","shell.execute_reply":"2022-04-04T10:58:34.521634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bz2\nimport pandas as pd\nimport re \nimport numpy as np","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T10:58:34.550663Z","iopub.execute_input":"2022-04-04T10:58:34.550972Z","iopub.status.idle":"2022-04-04T10:58:34.555309Z","shell.execute_reply.started":"2022-04-04T10:58:34.550943Z","shell.execute_reply":"2022-04-04T10:58:34.554164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import Dataset\ntrain_file = bz2.BZ2File('../input/amazonreviews/train.ft.txt.bz2')\ntest_file = bz2.BZ2File('../input/amazonreviews/test.ft.txt.bz2')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T10:58:34.587505Z","iopub.execute_input":"2022-04-04T10:58:34.587758Z","iopub.status.idle":"2022-04-04T10:58:34.593632Z","shell.execute_reply.started":"2022-04-04T10:58:34.587733Z","shell.execute_reply":"2022-04-04T10:58:34.592687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Reading Dataset***","metadata":{}},{"cell_type":"code","source":"#Reading Data set\ntrain_file = train_file.readlines()\ntest_file = test_file.readlines()\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T10:58:34.625411Z","iopub.execute_input":"2022-04-04T10:58:34.625674Z","iopub.status.idle":"2022-04-04T11:00:09.866928Z","shell.execute_reply.started":"2022-04-04T10:58:34.625643Z","shell.execute_reply":"2022-04-04T11:00:09.86609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of training reivews: \" + str(len(train_file)))\nprint(\"Number of test reviews: \" + str(len(test_file)))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T11:00:09.868652Z","iopub.execute_input":"2022-04-04T11:00:09.868992Z","iopub.status.idle":"2022-04-04T11:00:09.876881Z","shell.execute_reply.started":"2022-04-04T11:00:09.868955Z","shell.execute_reply":"2022-04-04T11:00:09.875715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training on the first 10000 reviews in the  dataset\nnum_train = 100000\n#Using 2000 reviews from test set\nnum_test = 20000#Using 200,000 reviews from test set\n\ntrain_file = [x.decode('utf-8') for x in train_file[:num_train]]\ntest_file = [x.decode('utf-8') for x in test_file[:num_test]]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T11:00:09.878594Z","iopub.execute_input":"2022-04-04T11:00:09.879477Z","iopub.status.idle":"2022-04-04T11:00:10.249567Z","shell.execute_reply.started":"2022-04-04T11:00:09.879437Z","shell.execute_reply":"2022-04-04T11:00:10.248799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracing Labels and Review from traing Dataset\ntrain_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\ntrain_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T11:00:10.250754Z","iopub.execute_input":"2022-04-04T11:00:10.251105Z","iopub.status.idle":"2022-04-04T11:00:10.811805Z","shell.execute_reply.started":"2022-04-04T11:00:10.251068Z","shell.execute_reply":"2022-04-04T11:00:10.811043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracing Labels and Review from test Dataset\ntest_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\ntest_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T11:00:10.815443Z","iopub.execute_input":"2022-04-04T11:00:10.815815Z","iopub.status.idle":"2022-04-04T11:00:10.933056Z","shell.execute_reply.started":"2022-04-04T11:00:10.815763Z","shell.execute_reply":"2022-04-04T11:00:10.932243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Creating Data Frame***","metadata":{}},{"cell_type":"code","source":"train = pd.DataFrame({'text':train_sentences,'label':train_labels})\ntest=pd.DataFrame({'text':test_sentences,'label':test_labels})","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:10.936213Z","iopub.execute_input":"2022-04-04T11:00:10.936572Z","iopub.status.idle":"2022-04-04T11:00:11.022556Z","shell.execute_reply.started":"2022-04-04T11:00:10.936533Z","shell.execute_reply":"2022-04-04T11:00:11.021855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:11.023771Z","iopub.execute_input":"2022-04-04T11:00:11.0242Z","iopub.status.idle":"2022-04-04T11:00:11.039593Z","shell.execute_reply.started":"2022-04-04T11:00:11.024164Z","shell.execute_reply":"2022-04-04T11:00:11.038564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:11.040814Z","iopub.execute_input":"2022-04-04T11:00:11.04128Z","iopub.status.idle":"2022-04-04T11:00:11.064037Z","shell.execute_reply.started":"2022-04-04T11:00:11.041242Z","shell.execute_reply":"2022-04-04T11:00:11.063249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['number_of_words'] = train['text'].str.lower().str.split().apply(len)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:11.065392Z","iopub.execute_input":"2022-04-04T11:00:11.065884Z","iopub.status.idle":"2022-04-04T11:00:12.398484Z","shell.execute_reply.started":"2022-04-04T11:00:11.065845Z","shell.execute_reply":"2022-04-04T11:00:12.397751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['number_of_words'] = test['text'].str.lower().str.split().apply(len)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:12.399909Z","iopub.execute_input":"2022-04-04T11:00:12.400274Z","iopub.status.idle":"2022-04-04T11:00:12.739505Z","shell.execute_reply.started":"2022-04-04T11:00:12.400227Z","shell.execute_reply":"2022-04-04T11:00:12.738792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Data Visulaization*","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.set(style=\"darkgrid\")\nsns.countplot(x=\"label\", data=train)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:12.740701Z","iopub.execute_input":"2022-04-04T11:00:12.741043Z","iopub.status.idle":"2022-04-04T11:00:13.629059Z","shell.execute_reply.started":"2022-04-04T11:00:12.741015Z","shell.execute_reply":"2022-04-04T11:00:13.628286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['number_of_words'].plot(bins=50, kind='hist',figsize = (10,8)) ","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:13.630402Z","iopub.execute_input":"2022-04-04T11:00:13.630799Z","iopub.status.idle":"2022-04-04T11:00:14.10221Z","shell.execute_reply.started":"2022-04-04T11:00:13.630753Z","shell.execute_reply":"2022-04-04T11:00:14.101494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hist(column='number_of_words', by='label',\n           bins=50,figsize=(14,6))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:14.104648Z","iopub.execute_input":"2022-04-04T11:00:14.104991Z","iopub.status.idle":"2022-04-04T11:00:14.675612Z","shell.execute_reply.started":"2022-04-04T11:00:14.104956Z","shell.execute_reply":"2022-04-04T11:00:14.674771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Data Preprocessing*","metadata":{}},{"cell_type":"code","source":"import re\n\nimport nltk\n\ndef remove_url(text):\n     url=re.compile(r\"https?://\\S+|www\\.\\S+\")\n     return url.sub(r\" \",text)\n\ndef remove_html(text):\n  cleanr = re.compile('<.*?>')\n  return cleanr.sub(r\" \",text)\n\n\n\ndef remove_num(texts):\n   output = re.sub(r'\\d+', '', texts)\n   return output\n\n\nimport string\ndef remove_punc(text):\n   table=str.maketrans(' ',' ',string.punctuation)\n   return text.translate(table)\n\n\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words(\"english\"))\n \ndef remove_stopword(text):\n   text=[word.lower() for word in text.split() if word.lower() not in stop]\n   return \" \".join(text)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:14.676914Z","iopub.execute_input":"2022-04-04T11:00:14.677413Z","iopub.status.idle":"2022-04-04T11:00:15.564548Z","shell.execute_reply.started":"2022-04-04T11:00:14.677372Z","shell.execute_reply":"2022-04-04T11:00:15.563525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text']=train.text.map(lambda x:remove_url(x))\ntrain['text']=train.text.map(lambda x:remove_html(x))\ntrain['text']=train.text.map(lambda x:remove_punc(x))\ntrain['text']=train['text'].map(remove_num)\ntrain['text']=train['text'].map(remove_stopword)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:15.565996Z","iopub.execute_input":"2022-04-04T11:00:15.566356Z","iopub.status.idle":"2022-04-04T11:00:22.098535Z","shell.execute_reply.started":"2022-04-04T11:00:15.566315Z","shell.execute_reply":"2022-04-04T11:00:22.097763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['text']=test.text.map(lambda x:remove_url(x))\ntest['text']=test.text.map(lambda x:remove_html(x))\ntest['text']=test.text.map(lambda x:remove_punc(x))\ntest['text']=test['text'].map(remove_num)\ntest['text']=test['text'].map(remove_stopword)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:22.100247Z","iopub.execute_input":"2022-04-04T11:00:22.100577Z","iopub.status.idle":"2022-04-04T11:00:23.394144Z","shell.execute_reply.started":"2022-04-04T11:00:22.100541Z","shell.execute_reply":"2022-04-04T11:00:23.393344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport nltk\n\ndef Stemming(text):\n   stem=[]\n   from nltk.corpus import stopwords\n   from nltk.stem import SnowballStemmer\n  #is based on The Porter Stemming Algorithm\n   stopword = stopwords.words('english')\n   snowball_stemmer = SnowballStemmer('english')\n   word_tokens = nltk.word_tokenize(text)\n   stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n   stem=' '.join(stemmed_word)\n   return stem","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:23.395929Z","iopub.execute_input":"2022-04-04T11:00:23.396429Z","iopub.status.idle":"2022-04-04T11:00:23.403525Z","shell.execute_reply.started":"2022-04-04T11:00:23.396387Z","shell.execute_reply":"2022-04-04T11:00:23.402713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain['text']=train['text'].map(Stemming)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:00:23.405042Z","iopub.execute_input":"2022-04-04T11:00:23.405453Z","iopub.status.idle":"2022-04-04T11:02:35.876954Z","shell.execute_reply.started":"2022-04-04T11:00:23.405413Z","shell.execute_reply":"2022-04-04T11:02:35.876106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest['text']=test['text'].map(Stemming)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:02:35.879187Z","iopub.execute_input":"2022-04-04T11:02:35.879549Z","iopub.status.idle":"2022-04-04T11:03:02.439557Z","shell.execute_reply.started":"2022-04-04T11:02:35.87951Z","shell.execute_reply":"2022-04-04T11:03:02.438723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-04T11:03:02.441156Z","iopub.execute_input":"2022-04-04T11:03:02.441473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  ***Word Embedding***","metadata":{}},{"cell_type":"code","source":"max_length=100\nvocab_size=12000\nembedding_dim=64\ntrunc_type=\"post\"\noov_tok=\"<OOV>\"\npadding_type=\"post\"\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_tok)\ntokenizer.fit_on_texts(train['text'])\n\nword_index = tokenizer.word_index\n\ntraining_sequences = tokenizer.texts_to_sequences(train['text'])\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\ntesting_sequences = tokenizer.texts_to_sequences(test['text'])\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_padded[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(training_sequences[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM,GRU\nfrom keras.preprocessing import sequence\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score    \nfrom tensorflow.python.keras import models, layers, optimizers   \nfrom keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, SpatialDropout1D\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Bidirectional LSTM Model*","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(Bidirectional(LSTM(256, dropout=0.2)))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\nmodel.summary()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adam=Adam(lr=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory=model.fit(training_padded,train['label'], epochs=15, batch_size=256,verbose = 1,callbacks = [EarlyStopping(monitor='val_accuracy', patience=2)],validation_data=(testing_padded,test['label']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Review(sentence):\n   sequences = tokenizer.texts_to_sequences(sentence)\n   padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\n   prob=model.predict(padded)\n   if prob>=0.8:\n     print(5)\n   elif prob>=0.6:\n     print(4)\n   elif prob>=0.4:\n     print(3) \n   elif prob>=0.2:\n     print(2)   \n   else:\n       print(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence=['Good Product + exactly in size']\nReview(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence=['this is worst thing donot buy it']\nReview(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting the Test set results\ny_pred = model.predict(testing_padded)\ny_pred = (y_pred > 0.5)\nX_test=testing_padded\ny_test=test['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy: %f' % accuracy)\n\nprecision = precision_score(y_test, y_pred)\nprint('Precision: %f' % precision)\n\nrecall = recall_score(y_test, y_pred)\nprint('Recall: %f' % recall)\n\nf1 = f1_score(y_test, y_pred)\nprint('F1 score: %f' % f1)\n \n# ROC AUC\nauc = roc_auc_score(y_test, y_pred)\nprint('ROC AUC: %f' % auc)\n# confusion matrix\nmatrix = confusion_matrix(y_test, y_pred)\nprint(matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\nimport seaborn as sns\nsns.heatmap(matrix,annot=True,fmt='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC Curve\n\nfrom sklearn.metrics import roc_curve\ny_pred_keras = model.predict(X_test).ravel()\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n\nfrom sklearn.metrics import auc\nauc_keras = auc(fpr_keras, tpr_keras)\n\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n# Zoom in view of the upper left corner.\nplt.figure(2)\nplt.xlim(0, 0.2)\nplt.ylim(0.8, 1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve (zoomed in at top left)')\nplt.legend(loc='best')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}